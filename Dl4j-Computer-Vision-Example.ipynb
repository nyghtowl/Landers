{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL4J Neural Net Computer Vision Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are machine learning algorithms used for classificaiton and prediction, which works well with high dimensionality data. This notebook provides sample code on how to structure, run and save a neural net using Deeplearning4j (DL4J) for a simplified computer vision problem. This notebook's example uses animal images with the goal to correctly identify the picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"nn_diagram.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural nets work especially well with image and text datasets that have many examples of each classification. The data is converted to a numerical representation and fed into the model where each node in the net applies a linear and non-linear transformation.\n",
    "\n",
    ">***linear equation***<br>\n",
    ">$\\mathbf{z_k}= \\sum_{j=1} \\mathbf{w_{k,j}}\\mathbf{x_j} + \\mathbf{b_k}$\n",
    "\n",
    "\n",
    ">***non-linear equation - sigmoid***<br>\n",
    ">$\\mathbf{y= \\dfrac{1}{(1+\\mathrm{e}^{-z})}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input ($\\mathbf{x}$) is the data fed into the net. Each node multiplies a weight ($\\mathbf{w}$) to the input, sums the product in that node and then applies a bias ($\\mathbf{b}$).  The network weights and bias, also known as parameters ($\\mathbf{\\theta}$), are used to fit the model to its objective (goal). In order to accomplish this, gradient descent optimization techniques are used to ***find the optimal weights*** that will lead to correct classification. Gradient descent uses the derivative (gradient) of the calculated model loss (prediction error) in order to shift each of the weights in the direction on the error curve that will reduce the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Extrema_example.svg/600px-Extrema_example.svg.png\">\n",
    "\n",
    "<center>- Wikipedia "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information on DL4J and how neural nets function can be found in the links below and the References section:\n",
    "- DL4J http://deeplearning4j.org/documentation.html\n",
    "- Neural Nets for Newbies https://youtu.be/Cu6A96TUy_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Java 7+](http://nd4j.org/getstarted.html#java)\n",
    "- [Maven 3.3.9](http://nd4j.org/getstarted.html#maven)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "//Below is for Jupyter-Scala notebook. If iScala is used then below should change to load dependencies\n",
    "load.resolver(\"DefaultMavenRepository\" at \"https://repo1.maven.org/maven2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdl4jVersion\u001b[0m: java.lang.String = \u001b[32m\"0.4-rc3.8\"\u001b[0m\n",
       "\u001b[36mnd4jVersion\u001b[0m: java.lang.String = \u001b[32m\"0.4-rc3.8\"\u001b[0m\n",
       "\u001b[36mcanovaVersion\u001b[0m: java.lang.String = \u001b[32m\"0.0.0.14\"\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val dl4jVersion = \"0.4-rc3.10\"\n",
    "val nd4jVersion = \"0.4-rc3.10\"\n",
    "val canovaVersion = \"0.0.0.16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load.ivy(\"org.deeplearning4j\" % \"deeplearning4j-core\" % dl4jVersion)\n",
    "load.ivy(\"org.deeplearning4j\" % \"deeplearning4j-nlp\" % dl4jVersion)\n",
    "load.ivy(\"org.deeplearning4j\" % \"deeplearning4j-ui\" % dl4jVersion)\n",
    "load.ivy(\"org.nd4j\" % \"nd4j-x86\" % nd4jVersion)\n",
    "load.ivy(\"canova-spark\" % \"org.nd4j\" % canovaVersion)\n",
    "load.ivy(\"canova-nd4j-codec\" % \"org.nd4j\" % canovaVersion)\n",
    "load.ivy(\"canova-nd4j-image\" % \"org.nd4j\" % canovaVersion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import java.io.{File, IOException}\n",
    "import java.util\n",
    "import java.util.Random\n",
    "\n",
    "import org.apache.commons.io.{FilenameUtils}\n",
    "import org.canova.api.io.filters.BalancedPathFilter\n",
    "import org.canova.api.io.labels.ParentPathLabelGenerator\n",
    "import org.canova.api.records.reader.RecordReader\n",
    "import org.canova.api.split.{FileSplit, InputSplit}\n",
    "import org.canova.image.loader.BaseImageLoader\n",
    "import org.canova.image.recordreader.ImageRecordReader\n",
    "import org.deeplearning4j.datasets.canova.RecordReaderDataSetIterator\n",
    "import org.deeplearning4j.datasets.iterator.{DataSetIterator, MultipleEpochsIterator}\n",
    "import org.deeplearning4j.nn.api.OptimizationAlgorithm\n",
    "import org.deeplearning4j.nn.conf.layers.{ConvolutionLayer, DenseLayer, LocalResponseNormalization, OutputLayer, SubsamplingLayer}\n",
    "import org.deeplearning4j.nn.conf.{GradientNormalization, MultiLayerConfiguration, NeuralNetConfiguration, Updater}\n",
    "import org.deeplearning4j.nn.multilayer.MultiLayerNetwork\n",
    "import org.deeplearning4j.nn.weights.WeightInit\n",
    "import org.deeplearning4j.optimize.listeners.ScoreIterationListener\n",
    "import org.deeplearning4j.util.NetSaverLoaderUtils\n",
    "import org.nd4j.linalg.dataset.DataSet\n",
    "import org.nd4j.linalg.lossfunctions.LossFunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to clean up and load the data for training and testing.\n",
    "- store the data in a folder that the model can load from\n",
    "- confirm the formats are the same (e.g. pictures exist and have similar sizes)\n",
    "- convert data to a DataSet structure (numerical feature format and labels)\n",
    "- setup the data to load in batches inside an iterator\n",
    "\n",
    "Something to be aware of with data is the difference between supervised and unsupervised which just means labeled and unlabeled. In this example, we have labeled images we are working with; thus, it's supervised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images provided in this example are from the U.S Fish and Wildlife Service and they are in the public domain. There are four categories with ~ 20 images each, in the dataset and the categories are:\n",
    "\n",
    "- bear\n",
    "- deer\n",
    "- duck\n",
    "- turtle\n",
    "\n",
    "The images vary in pixel size, and they are all RGB encoded, which means they have 3 color channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>***Image Example***</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"animals/turtle/Blandings_Turtle.jpg\">\n",
    "<center> - U.S. Fish and Wildlife Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is used to load the data into a DataSetIterator format that can be fed into the network. ImageRecordReader handles loading and vectorizing the images, and  RecordReaderDataSetIterator converts images into a DataSet format. It generates the iterator that will only load the data when next is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Load images and labels\n",
    "val height = 50\n",
    "val width = 50\n",
    "val channels = 3\n",
    "val numExamples = 80\n",
    "val numLabels = 4\n",
    "val batchSize = 20\n",
    "val splitTrainTest = 0.8\n",
    "val rng = new Random(seed)\n",
    "val labelPosition = 1\n",
    "\n",
    "val mainPath: File = new File(\"animals\") \n",
    "\n",
    "// Define how to filter and load data into batches\n",
    "val recordReader: RecordReader = new ImageRecordReader(width, height, channels, new ParentPathLabelGenerator())\n",
    "val fileSplit: FileSplit = new FileSplit(mainPath, BaseImageLoader.ALLOWED_FORMATS,rng)\n",
    "val pathFilter: BalancedPathFilter = new BalancedPathFilter(rng, BaseImageLoader.ALLOWED_FORMATS, new ParentPathLabelGenerator, numExamples, numLabels, 0, batchSize)\n",
    "\n",
    "// Define train and test split\n",
    "val inputSplit: Array[InputSplit] = fileSplit.sample(pathFilter, numExamples * (1 + splitTrainTest), numExamples * (1 - splitTrainTest))\n",
    "val trainData: InputSplit = inputSplit(0)\n",
    "val testData: InputSplit = inputSplit(1)\n",
    "\n",
    "// Define how to load data into network\n",
    "try {\n",
    "  recordReader.initialize(trainData)\n",
    "} catch {\n",
    "  case ioe: IOException => ioe.printStackTrace()\n",
    "  case e: InterruptedException => e.printStackTrace()\n",
    "}\n",
    "var dataIter: DataSetIterator = new RecordReaderDataSetIterator(recordReader, batchSize, labelPosition, numLabels)\n",
    "val multDataIter: MultipleEpochsIterator = new MultipleEpochsIterator(epochs, dataIter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with computer vision models, you will want many more examples to run through your model for it to build a solid representation of the different animals. The sample set is too small to achieve high accuracy scores. Some approaches to expand the dataset when you have sparse examples are the following:\n",
    "- flip images by various degrees\n",
    "- change the color saturation (including change to grey scale)\n",
    "- change image contrast or brightness\n",
    "- crop the image in different positions\n",
    "- search and download more examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Model configuration takes experimentation to get familiar with all the options. Below outlines key attributes that you can define in the your configuration:\n",
    "\n",
    "- ***weightInit*** = how to initialize weights which is typically a variation on random unless you load weights defined from a previous model\n",
    "- ***seed*** = locks random weight initialization for consistent results when checking and adjusting hyperparameter impact\n",
    "- ***activation*** = non-linear function applied to the output of each node in the layer\n",
    "- ***iterations*** = how many times to run each batch through each layer\n",
    "- ***optimizationAlgo*** = convex optimizer that calculates and applies loss function gradients to parameter updates\n",
    "- ***updater*** = equation applies gradient adjustments (e.g. Nesterovs applies momentum to the learning rate for the gradient update)\n",
    "- ***learningRate ($\\alpha$)*** = the step to take down or up the optimizer algorithm to improve model convergence\n",
    "- ***regularization*** = whether to apply weight decay to penalize large weights and bias and prevent overfitting (e.g. $\\ell1$ is best for sparse data and $\\ell2$ is good with minimizing prediction error)\n",
    "- ***gradientNormalization*** = regularization approach to smooth gradient results\n",
    "- ***layer*** = construct to define each layer and requires a name or number when there is more than one layer\n",
    "- ***backprop*** = true or false signals whether to apply backprop to the model for weight updates\n",
    "\n",
    "Note, most of these can be defined globally or inside the construct of each layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val seed = 42\n",
    "val iterations = 1\n",
    "val epochs = 5\n",
    "val listenerFreq = 1\n",
    "val weightInit = WeightInit.XAVIER\n",
    "val activation = \"relu\"\n",
    "val optimizer = OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Computer Vision Common Configuration***<br>\n",
    "It's good to start with common configuration approaches like the ones provided below, and use training and tunning to modify hyperparameters. More information on this topic is covered in the Tuning section. \n",
    "\n",
    "- ***WeightInit.XAVIER*** = initializing weights in network by drawing them from uniform distribution and dividing by weight matrix size\n",
    "> $\\mathbf{w = \\dfrac{1}{\\sqrt{n_{in}+ n_{out}}}}$\n",
    "- ***\"relu\"*** = rectifed linear unit is an activation function that helps prevent gradient vanishing because it sets the activation threshold at zero\n",
    "> $\\mathbf{f(x)=max(0,x)}$\n",
    "- ***LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD*** *(aka cross-entropy)* = evaluates and scores model error in the output layer\n",
    "> $\\mathbf{H_y{'}(y) = -\\sum_{i}y_i^{'}log(y_i)}$\n",
    "- ***OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT*** = how to update weights & bias based on error gradient from the full training set and the updater changes\n",
    "> $\\mathbf{w = w -\\alpha(H_y{'}(y))}$ <br>\n",
    "> $\\mathbf{b = b -\\alpha(H_y{'}(y))}$\n",
    "- ***ConvolutionLayer*** = type of feed-forward net where nodes are tiled to respond to overlapping regions in the dataset and kernel size, stride, padding and number of feature matrices are used to convolve (reshape) the input\n",
    "- ***SubsamplingLayer*** = layer type that reduces the dimension of the signal and typically applies kernal size of 2 or 3 with a stride of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tiny ImageNet Example***<br>\n",
    "Below are two different example configurations. First, is pulled from the Tiny ImageNet paper that provides guidance on how to build as compact a deep model as possible to be effective in image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Tiny ImageNet Example\n",
    "val confTiny: MultiLayerConfiguration = new NeuralNetConfiguration.Builder()\n",
    "  .weightInit(weightInit)\n",
    "  .seed(seed)\n",
    "  .activation(activation)\n",
    "  .iterations(iterations)\n",
    "  .gradientNormalization(GradientNormalization.RenormalizeL2PerLayer)\n",
    "  .optimizationAlgo(optimizer)\n",
    "  .updater(Updater.NESTEROVS)\n",
    "  .learningRate(0.01)\n",
    "  .momentum(0.9)\n",
    "  .regularization(true)\n",
    "  .l2(0.04)\n",
    "  .list()\n",
    "  .layer(0, new ConvolutionLayer.Builder(5, 5)\n",
    "    .name(\"cnn1\")\n",
    "    .nIn(channels)\n",
    "    .stride(1, 1)\n",
    "    .padding(2, 2)\n",
    "    .nOut(32)\n",
    "    .build())\n",
    "  .layer(1, new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX)\n",
    "    .kernelSize(3, 3)\n",
    "    .name(\"pool1\")\n",
    "    .build())\n",
    "  .layer(2, new LocalResponseNormalization.Builder(3, 5e-05, 0.75).build())\n",
    "  .layer(3, new ConvolutionLayer.Builder(5, 5)\n",
    "    .name(\"cnn2\")\n",
    "    .stride(1, 1)\n",
    "    .padding(2, 2)\n",
    "    .nOut(32)\n",
    "    .build())\n",
    "  .layer(4, new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX)\n",
    "    .kernelSize(3, 3)\n",
    "    .name(\"pool2\")\n",
    "    .build())\n",
    "  .layer(5, new LocalResponseNormalization.Builder(3, 5e-05, 0.75).build())\n",
    "  .layer(6, new ConvolutionLayer.Builder(5, 5)\n",
    "    .name(\"cnn3\")\n",
    "    .stride(1, 1)\n",
    "    .padding(2, 2)\n",
    "    .nOut(64)\n",
    "    .build())\n",
    "  .layer(7, new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX)\n",
    "    .kernelSize(3, 3)\n",
    "    .name(\"pool3\")\n",
    "    .build())\n",
    "  .layer(8, new DenseLayer.Builder()\n",
    "    .name(\"ffn1\")\n",
    "    .nOut(250)\n",
    "    .dropOut(0.5)\n",
    "    .build())\n",
    "  .layer(9, new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)\n",
    "    .nOut(numLabels)\n",
    "    .activation(\"softmax\")\n",
    "    .build())\n",
    "  .backprop(true).pretrain(false)\n",
    "  .cnnInputSize(height, width, channels).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***AlexNet Example***<br>\n",
    " The second configuration is a slight variant on AlexNet which won the ImageNet competition in 2012 for image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// AlexNet Example\n",
    "val nonZeroBias = 1\n",
    "val dropOut = 0.5\n",
    "val poolingType: SubsamplingLayer.PoolingType = SubsamplingLayer.PoolingType.MAX\n",
    "\n",
    "val confAlexNet: MultiLayerConfiguration = new NeuralNetConfiguration.Builder()\n",
    "    .weightInit(weightInit)\n",
    "    .seed(seed)\n",
    "    .activation(activation)\n",
    "    .iterations(iterations)\n",
    "    // normalize to prevent vanishing or exploding gradients\n",
    "    .gradientNormalization(GradientNormalization.RenormalizeL2PerLayer) \n",
    "    .optimizationAlgo(optimizer)\n",
    "    .updater(Updater.NESTEROVS)\n",
    "    .learningRate(1e-3)\n",
    "    .momentum(0.9)\n",
    "    .regularization(true)\n",
    "    .l2(5 * 1e-4)\n",
    "    .miniBatch(false)\n",
    "    .list()\n",
    "    .layer(0, new ConvolutionLayer.Builder(new int[]{11, 11}, new int[]{4, 4}, new int[]{3, 3})\n",
    "            .name(\"cnn1\")\n",
    "            .nIn(channels)\n",
    "            .nOut(96)\n",
    "            .build())\n",
    "    .layer(1, new LocalResponseNormalization.Builder()\n",
    "            .name(\"lrn1\")\n",
    "            .build())\n",
    "    .layer(2, new SubsamplingLayer.Builder(poolingType, new int[]{3, 3}, new int[]{2, 2})\n",
    "            .name(\"pool1\")\n",
    "            .build())\n",
    "            //conv2\n",
    "    .layer(3, new ConvolutionLayer.Builder(new int[]{5, 5}, new int[]{1, 1}, new int[]{2, 2})\n",
    "            .name(\"cnn2\")\n",
    "            .nOut(256)\n",
    "            .biasInit(nonZeroBias)\n",
    "            .build())\n",
    "    .layer(4, new LocalResponseNormalization.Builder()\n",
    "            .name(\"lrn2\")\n",
    "            .k(2).n(5).alpha(1e-4).beta(0.75)\n",
    "            .build())\n",
    "    .layer(5, new SubsamplingLayer.Builder(poolingType, new int[]{3, 3}, new int[]{2, 2})\n",
    "            .name(\"pool2\")\n",
    "            .build())\n",
    "    .layer(6, new ConvolutionLayer.Builder(new int[]{3, 3}, new int[]{1, 1}, new int[]{1, 1})\n",
    "            .name(\"cnn3\")\n",
    "            .nOut(384)\n",
    "            .build())\n",
    "    .layer(7, new ConvolutionLayer.Builder(new int[]{3, 3}, new int[]{1, 1}, new int[]{1, 1})\n",
    "            .name(\"cnn4\")\n",
    "            .nOut(384)\n",
    "            .biasInit(nonZeroBias)\n",
    "            .build())\n",
    "    .layer(8, new ConvolutionLayer.Builder(new int[]{3, 3}, new int[]{1, 1}, new int[]{1, 1})\n",
    "            .name(\"cnn5\")\n",
    "            .nOut(256)\n",
    "            .biasInit(nonZeroBias)\n",
    "            .build())\n",
    "    .layer(9, new SubsamplingLayer.Builder(poolingType, new int[]{3, 3}, new int[]{2, 2})\n",
    "            .name(\"pool3\")\n",
    "            .build())\n",
    "    .layer(10, new DenseLayer.Builder()\n",
    "            .name(\"ffn1\")\n",
    "            .nOut(4096)\n",
    "            .biasInit(nonZeroBias)\n",
    "            .dropOut(dropOut)\n",
    "            .build())\n",
    "    .layer(11, new DenseLayer.Builder()\n",
    "            .name(\"ffn2\")\n",
    "            .nOut(4096)\n",
    "            .biasInit(nonZeroBias)\n",
    "            .dropOut(dropOut)\n",
    "            .build())\n",
    "    .layer(12, new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)\n",
    "            .name(\"output\")\n",
    "            .nOut(numLabels)\n",
    "            .activation(\"softmax\")\n",
    "            .build())\n",
    "    .backprop(true)\n",
    "    .pretrain(false)\n",
    "    .cnnInputSize(height,width,channels).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Initialize the network and alternate which configuration to pass into MultiLayerNetwork\n",
    "val network: MultiLayerNetwork = new MultiLayerNetwork(confTiny)\n",
    "network.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Listeners***\n",
    "\n",
    "Apply setListeners to the network to get information on how the model is performing. ScoreIterationListener is the simplest one to check if the model is converging in its predictions on the training data. Basically it shows how accurately the model is predicting the results of the training data. Typically, you work to lower the scores as close to zero as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network.setListeners(new ScoreIterationListener(listenerFreq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Gradients***\n",
    "\n",
    "Backpropagation is how you move the weight updates from stochastic gradient descent back into the model. Sometimes there are score results of NaN or 0 because the gradient explodes or vanishes. As changes are moved backwards through the layers in deep nets, if the gradient starts out too small then it can vanish causing the neurons in the beginning layers to learn more slowly than the neurons in the later layers. If the gradient starts out to big it can explode and no longer be useful for changes that the model can get signal on. More information on how to address these issues are in the References section. Just be aware this is common and requires tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've loaded the data and initialized the model configuration, train the model by calling fit on the configured network and passing in the dataset. The goal of training is to find weights and bias that will help the model classify with high accuracy while generalizing enough to perform well on new data the model hasn't seen yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network.fit(multDataIter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next to loading data and training time, tuning is a one of the key challenges to produce effective neural nets. Tuning refers to the process of selecting hyperparameters (such as the learning rate) in order to obtain good performance. If these hyperparameters are poorly chosen, the network may learn very slowly, or frequently may not learn at all.\n",
    "\n",
    "To get a good sense of how to tune, spend time running different models and reading academic papers that outline various approaches. Below are a couple pointers to get you started:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***General***\n",
    "\n",
    "Start with as few hyperparameters as possible in the configuration and focus on improving scores with those first. Try tuning one hyperparameter at a time and keep the others fixed. When it seems you can no longer improve the scores on it, change to a new one and be willing to go back to the first after you've made adjustments to other hyperparameters. \n",
    "\n",
    "***Learning Rate***\n",
    "\n",
    "Learning rate is a good one to start with. Watch how the score changes. If it decreases smoothly till the final epoch, that's a good value to work with. If the score's progress is smooth early on and then has small random oscillations, or if the score climbs, then increase the learning rate. If the score has large oscillations from the start then decrease the learning rate. Initially, try shifting the rate by an order magnitude of 10 and then make smaller adjustments as you get closer to a smooth decrease in score.\n",
    "\n",
    "***Mini-batch Size***\n",
    "\n",
    "Mini-batch size makes a difference when tuning. If its too small then you aren't maximizing matrix library optimizations and too large leads to not updating the weights enough. Be aware that the size is independent of other hyperparameters; thus, you don't need tuned hyperparameters to find a good mini-batch size. Review how quickly you can improve accuracy to determine what size will work best. Common mini-batch sizes range between 30-120.\n",
    "\n",
    "***Batch Normalization***\n",
    "\n",
    "Batch normalization is the popular technique in the last year for deep neural net training because it leads to faster learning and higher overall accuracy. You can work with higher learning rates and avoid using regularization techniques like dropout. When passing in input, it is common to scale the input by shifting it to zero-mean and unit variance, but as the input passes through the net, it gets adjusted by the weights and bias which is known as \"covariate shift\". Using batch norm in each mini-batch and between layers helps to reset the input normalization.\n",
    "\n",
    "***Automated Tuning***\n",
    "\n",
    "Manual tuning is great to get a feel on how to use hyperparameters, but when you want to get quick results, automated tuning techniques will help cut down training time. There are many different approaches to try like grid, random and Bayesian hyperparameter optimization. \n",
    "\n",
    "\n",
    "For more information on tuning, check out the references below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model converges with regard to its loss function, you can run new test data through the model to see how well it generalizes its predictions. The test data should be a dataset that was not seen during training.\n",
    "\n",
    "Example performance indicators:\n",
    "- ***accuracy*** = number of correct predictions divided by total test examples \n",
    "- ***precision*** = number of correct positive predictions divided by total positive class values predicted\n",
    "- ***recall*** = number of correct positive predictions divided by the total actual positive class values\n",
    "- ***f1-score*** = measure of test accuracy as a balance between precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recordReader.initialize(testData)\n",
    "dataIter = new RecordReaderDataSetIterator(recordReader, 20, 1, numLabels)\n",
    "val eval = network.evaluate(dataIter, dataIter.getLabels())\n",
    "print(eval.stats(true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model configuration and parameters(weights & bias) when you are satisfied with its evaluation scores, or when you need to take a break from training and don't want to loose the progress you've made. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val basePath = FilenameUtils.concat(System.getProperty(\"user.dir\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NetSaverLoaderUtils.saveNetworkAndParameters(network, basePath)\n",
    "NetSaverLoaderUtils.saveUpdators(network, basePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have trained, tuned, evaluated and saved your network and parameters, you can work on applying it to new image datasets and other problems. Go forth and have fun classifying images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For more information on how to develop neural nets as well as the datasets used here, below are additional resources to explore.\n",
    "\n",
    "- Skymind: http://www.skymind.io/\n",
    "- Tiny ImageNet Classification with CNN: http://cs231n.stanford.edu/reports/leonyao_final.pdf\n",
    "- AlexNet: http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf & https://github.com/BVLC/caffe/blob/master/models/bvlc_alexnet/train_val.prototxt\n",
    "- Neural Networks and Deep Learning: http://neuralnetworksanddeeplearning.com/chap3.html\n",
    "- Neuarl Networks: http://nbviewer.jupyter.org/github/masinoa/machine_learning/blob/master/04_Neural_Networks.ipynb\n",
    "- Visual Information Theory: https://colah.github.io/posts/2015-09-Visual-Information/\n",
    "- Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift: http://jmlr.org/proceedings/papers/v37/ioffe15.pdf\n",
    "- Deep Learning Book: http://www.deeplearningbook.org/\n",
    "- Neural Networks for Machine Learning: https://www.coursera.org/course/neuralnets\n",
    "- Convolutional Neural Networks for Visual Recognition: http://cs231n.github.io/\n",
    "- ImageNet: http://image-net.org/\n",
    "- U.S. Fish and Wildlife Service (animal sample dataset): http://digitalmedia.fws.gov/cdm/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.10",
   "language": "scala210",
   "name": "scala210"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": "scala",
   "mimetype": "text/x-scala",
   "name": "scala210",
   "pygments_lexer": "scala",
   "version": "2.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
